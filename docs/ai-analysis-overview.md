# Обзор AI-анализа компаний

Ниже описано, как работает пайплайн AI-анализа и как пишутся вспомогательные логи. Схема
поведения повторяет PHP-прокси из Bitrix-приложения: есть фоновая очередь, обработчик с
ретраями сетевых шагов и журнал событий `ai_debug_events`, который помогает разбирать
трафик и ошибки.

## Входные сценарии и запросы
1. Автозагрузка карточки компании: UI отправляет `GET /api/ai-analysis/run?inn=...` (в
   веб-прокси пример — `GET /v1/lookup/{inn}/ai-analyzer`). Ответ сразу передаётся в UI
   без постановки в очередь.
2. Запуск по кнопке/массовая постановка: `POST /api/ai-analysis/run` с телом вида
   `{ inns: ['7707083893'], mode: 'full'|'steps', steps?: string[] }`. Внутри шаги и
   режимы нормализуются так же, как в PHP-прокси: сохраняются домены/почты/имя компании,
   а дальше по ним строятся обращения к интеграции.
3. Остановка: `POST /api/ai-analysis/stop` кладёт команду `stop` для указанных ИНН; при
   следующей выборке из очереди обработчик пропустит элемент и залогирует уведомление.

## Постановка компаний в очередь
1. Вызов `POST /api/ai-analysis/run` принимает список ИНН и режим работы (`full` или `steps`). Если режим не заблокирован конфигурацией, он берётся из тела запроса, иначе — принудительный (`AI_ANALYZE_FORCED_MODE`).
2. Тело запроса нормализуется в полезную нагрузку: `{ source, count, requested_at, mode, steps|null, defer_count: 0, completed_steps: [] }`. Отсутствие интеграции (`AI_INTEGRATION_BASE`/`ANALYZE_BASE`) или падение `/health` возвращают ошибку 5xx без записи в очередь.
3. Для каждого ИНН делается upsert в `ai_analysis_queue`: устанавливаются `queued_at`, `queued_by` (из сессии) и сериализованный `payload`. Параллельно в `dadata_result` проставляется статус `queued`, сбрасываются даты старта/финиша и прогресс.
4. В лог `ai_debug_events` добавляется уведомление о постановке в очередь c полями `{inns, requestedBy, mode, steps, source}`. UI сразу видит новые статусы и может фильтровать по событиям.

## Запуск фонового обработчика
1. После ответа клиенту бэкенд пытается взять advisory-lock с ключом `42111` — это исключает одновременную работу нескольких обработчиков очереди.
2. Пока блокировка удерживается, обработчик повторяет цикл: достаёт самый старый `queued_at` из `ai_analysis_queue` (`FOR UPDATE SKIP LOCKED`), помечает его как взятый в работу и удаляет из таблицы.
3. Перед выполнением проверяются команды остановки в `ai_analysis_commands`. Если найден стоп для конкретного ИНН, элемент пропускается: статус не меняется, в лог пишется уведомление об отмене.

## Подготовка к анализу
1. Для выбранного ИНН читается список доступных колонок в `dadata_result` (статус, прогресс, флаги ошибок). Затем `markRunning` ставит `status = 'running'`, обнуляет прогресс и флаги ошибок, сбрасывает `finished_at`.
2. В лог пишется уведомление `analysis_start` с названием компании; при этом в `dadata_result` по возможности фиксируются `server_error = 0`, `analysis_ok = 0`, `analysis_started_at = now()`.

## Выполнение шагов (что отправляем и что получаем)
1. Определение плана:
   - Режим `full`: вызывается `runFullPipeline`, который один раз шлёт `POST /v1/pipeline/full` с `{ inn }` и ждёт один ответ.
   - Режим `steps`: формируется список шагов с основной точкой входа и fallback-эндпоинтами из `STEP_DEFINITIONS`.
2. Набор шагов и адресов совпадает с PHP-примером (маршрут `/v1/...`):
   - `lookup`: `GET /v1/lookup/{inn}/card` → JSON карточки компании; если недоступно, `POST /v1/lookup/card` c `{inn}`.
   - `parse_site`: `POST /v1/parse-site` c `{ inn }` плюс собранные домены/почты; fallback — `GET /v1/parse-site/{inn}`.
   - `analyze_json`: `GET /v1/analyze-json/{inn}` или `POST /v1/analyze-json` c `{inn}`.
   - `ib_match`: `GET /v1/ib-match/by-inn?inn=...`, fallback — `POST /v1/ib-match` или `/v1/ib-match/by-inn` с `{inn}`.
   - `equipment_selection`: `GET /v1/equipment-selection/by-inn/{inn}`.
3. Перед каждым сетевым вызовом проверяется `/health` интеграции. Если сервис недоступен,
   логируется ошибка `server_retry`/`server_stop` и попытка повторяется либо завершается
   по тайм-ауту.
4. Для каждого шага создаётся `requestId`, чтобы связать запрос и ответ:
   - Отправляем HTTP-запрос (метод из шага, путь `/v1/...`, тело обычно `{ inn }` или
     `{ inn, domain, parse_domains, ... }`). В лог попадает событие `request` с
     `source=ai-integration`, `requestId`, путём и телом.
   - Если основной эндпоинт отвечает ошибкой/тайм-аутом, пробуем fallback-список в том же
     формате и логируем каждую попытку.
   - На успешный ответ пишется `response` с `payload` (JSON тела). При неуспехе — `error`
     с текстом ошибки и счётчиком `attempt`.
5. Количество попыток шага — до трёх. Между попытками ставится пауза 2 секунды и
   уведомление о повторе. Тайм-аут одного шага регулируется `AI_INTEGRATION_STEP_TIMEOUT_MS`
   (по умолчанию 5 минут); общий тайм-аут всего пайплайна —
   `AI_INTEGRATION_OVERALL_TIMEOUT_MS` (10 минут).
6. После успешного шага обновляется прогресс в `dadata_result` (доля выполненных шагов или
   `1` для полного режима) и дописывается `completed_steps` в полезную нагрузку для
   возможного возобновления.

### Линейный план запросов (что отправляем → что ожидаем → что делаем дальше)
1. `POST /api/ai-analysis/run` с `{ inns, mode, steps? }` → подтверждение постановки в очередь → обработчик берёт ИНН в работу.
2. (Перед каждым сетевым шагом) `GET /health` интеграции без тела → `200 OK` → продолжаем; иначе фиксируем `server_retry` или останавливаем по тайм-ауту.
3. `GET /v1/lookup/{inn}/card` (или `POST /v1/lookup/card {inn}`) → карточка компании {id, domains} → обновляем прогресс, передаём домен дальше.
4. `POST /v1/parse-site { inn, domain?, parse_domains[], parse_emails[], company_name?, portal_domain?, company_id? }` → JSON с итогами парсинга {planned_domains, successful_domains, chunks_inserted} → пишем прогресс.
5. `GET /v1/analyze-json/{inn}` (или `POST /v1/analyze-json {inn}`) → {status, text_length, total_text_length, domains_processed, ai?} → обновляем прогресс.
6. `GET /v1/ib-match/by-inn?inn=...` (fallback `POST /v1/ib-match`/`/by-inn {inn}`) → {summary, duration_ms} → логируем и обновляем прогресс.
7. `GET /v1/equipment-selection/by-inn/{inn}` → {goods_types, site_equipment, log} → прогресс.
8. `GET /v1/lookup/{inn}/ai-analyzer` → итоговый ответ AI {ai, company, sites...} → записываем в UI/БД, помечаем анализ завершённым.
9. При ошибке на любом шаге: фиксируем событие `error`, возвращаем в очередь с `defer_count+1` (макс. 3) и списком успешных шагов; после исчерпания попыток — статус `failed`.
10. При получении команды `stop` или успешном завершении всех шагов: ставим статус `completed`/`stopped`, пишем `analysis_success` или уведомление об отмене, снимаем блокировку обработчика.

## Завершение и повторные попытки
1. Когда все выбранные шаги завершены, элемент удаляется из очереди. Если в этот момент поступил стоп-сигнал, статус помечается как остановленный, пишется уведомление, остальные действия пропускаются.
2. При успехе вызывается `markFinished` со статусом `completed`, фиксируются длительность и прогресс `1`. В лог уходит `analysis_success`, а в `dadata_result` проставляется `analysis_ok = 1` и сбрасывается `server_error`.
3. При ошибке статус становится `failed`, прогресс и выполненные шаги сохраняются. В лог пишется событие `error` с причиной. Если `defer_count < 3`, компания возвращается в очередь с увеличенным счётчиком и списком завершённых шагов, чтобы при следующем запуске пропустить успешные части.
4. Когда очередь опустела, пишется итоговое уведомление с количеством успешных, отложенных и ошибочных компаний, чтобы видеть общий результат прохода.

## Где и как пишутся логи
1. `logAiDebugEvent` при первом вызове создаёт таблицу `ai_debug_events` и индексы. Попытки добавить флаги в `dadata_result` (колонки `server_error`, `analysis_ok`, `analysis_started_at`) оборачиваются в try/catch, чтобы отсутствие колонок не ломало логирование.
2. События делятся на категории: трафик (`request`/`response`), ошибки (`error` с `errorKey`), уведомления (`notification` c `notificationKey`). Для уведомлений шаблоны формируют читаемые сообщения вроде «Начат анализ компании …».
3. При записи уведомлений или ошибок система пытается обновить служебные флаги в `dadata_result`; если это не удалось, в stdout пишется предупреждение, но сама запись в лог остаётся доступной.
